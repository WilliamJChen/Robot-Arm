Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
2232000,1.4471091,481.95652173913044,10.935685,73.07044896212491,73.07044896212491,1.0
2244000,1.4473325,500.0,11.141126,76.06666056315105,76.06666056315105,1.0
2256000,1.4481226,500.0,11.193423,76.33749389648438,76.33749389648438,1.0
2268000,1.4471025,500.0,11.3218,76.31666056315105,76.31666056315105,1.0
2280000,1.4472173,485.08,11.523403,74.06599456787109,74.06599456787109,1.0
2292000,1.4461286,468.11538461538464,11.588913,71.04230271852933,71.04230271852933,1.0
2304000,1.4462018,491.4166666666667,11.710324,74.85624424616496,74.85624424616496,1.0
2316000,1.4468604,484.2,11.744023,73.75399429321288,73.75399429321288,1.0
2328000,1.4474125,500.0,11.779096,76.02499389648438,76.02499389648438,1.0
2340000,1.4480934,494.2916666666667,11.884702,75.54374408721924,75.54374408721924,1.0
2352000,1.4471531,500.0,12.008321,76.1708272298177,76.1708272298177,1.0
2364000,1.4471672,490.9583333333333,12.04895,74.84999418258667,74.84999418258667,1.0
2376000,1.4472697,494.5833333333333,12.069209,75.16457748413086,75.16457748413086,1.0
2388000,1.4468536,480.76,12.2331505,73.39999542236328,73.39999542236328,1.0
2400000,1.4466351,453.8888888888889,12.2308655,69.07036597640426,69.07036597640426,1.0
2412000,1.4467176,471.56,12.298585,71.6059944152832,71.6059944152832,1.0
2424000,1.4468772,487.28,12.208,74.26999465942383,74.26999465942383,1.0
2436000,1.446514,494.5416666666667,12.360965,75.45624415079753,75.45624415079753,1.0
2448000,1.4463724,500.0,12.421939,76.1708272298177,76.1708272298177,1.0
2460000,1.4463499,477.72,12.34824,72.66999481201172,72.66999481201172,1.0
2472000,1.4462585,471.44,12.46352,71.79399459838868,71.79399459838868,1.0
2484000,1.4461908,485.92,12.318592,73.8859942626953,73.8859942626953,1.0
2496000,1.446159,490.5,12.420306,74.9062442779541,74.9062442779541,1.0
