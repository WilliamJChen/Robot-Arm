Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
10000,1.4189383,41.84615384615385,-708.56854,3.2093603396108734,3.2093603396108734,1.0
20000,1.4200982,35.786764705882355,-419.14252,2.595871114555527,2.595871114555527,1.0
30000,1.4219015,35.40875912408759,-251.48865,2.559612943308197,2.559612943308197,1.0
40000,1.424068,36.12592592592593,-135.7518,2.628859042238306,2.628859042238306,1.0
50000,1.4252166,35.800738007380076,-74.03205,2.595870629007966,2.595870629007966,1.0
60000,1.4267598,35.91881918819188,-38.101097,2.6074942389977376,2.6074942389977376,1.0
70000,1.4309645,36.0,-15.663925,2.6125479592217338,2.6125479592217338,1.0
80000,1.4357009,35.7032967032967,-5.6686196,2.583263527342688,2.583263527342688,1.0
90000,1.4384959,35.46715328467153,-2.5292342,2.56560561082659,2.56560561082659,1.0
100000,1.442213,35.65567765567766,-1.7654483,2.5783294557215095,2.5783294557215095,1.0
110000,1.4449993,35.62271062271062,-1.2087349,2.5753623993842156,2.5753623993842156,1.0
120000,1.4483701,35.896678966789665,-0.8335773,2.607291295519614,2.607291295519614,1.0
130000,1.4500785,35.7032967032967,-0.42795074,2.5860107862032375,2.5860107862032375,1.0
